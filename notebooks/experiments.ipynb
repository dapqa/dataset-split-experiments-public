{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The notebook contains experiments' code as they described in the paper."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os.path\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "from dfmf.model import SVDpp, SVD\n",
    "from dfmf.util import sort_by_user\n",
    "from drsu.config import DRSUConfiguration\n",
    "from drsu.datasets import ALL_DESCRIPTORS, as_numpy, download_and_transform_dataset\n",
    "\n",
    "from strategy import *\n",
    "from util.metrics import rmse, ndcg_at_k\n",
    "\n",
    "DRSUConfiguration.local_dataset_dir = '../data'\n",
    "RESULTS_DIR = '../results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Datasets:  ['Movielens 100k', 'Movielens 1M', 'Movielens 10M', 'epinions', 'LibraryThing', 'GoodRead Reviews (w/ spoilers)', 'Drug Recommendations', 'Amazon Ratings (Software)', 'Amazon Ratings (Amazon Fashion)', 'Amazon Ratings (All Beauty)', 'Amazon Ratings (Appliances)', 'Amazon Ratings (Gift Cards)', 'Amazon Ratings (Luxury Beauty)', 'Amazon Ratings (Magazine Subscriptions)', 'Amazon Ratings (Prime Pantry)']\n"
     ]
    }
   ],
   "source": [
    "DATASETS = []\n",
    "for dd in ALL_DESCRIPTORS:\n",
    "    if dd.id.startswith('amz_'):\n",
    "        if dd.n_rows > 1000000:\n",
    "            continue\n",
    "\n",
    "    DATASETS.append(dd)\n",
    "\n",
    "print('Chosen Datasets: ', [dd.name for dd in DATASETS])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Movielens 100k\" ready\n",
      "\"Movielens 1M\" ready\n",
      "\"Movielens 10M\" ready\n",
      "\"epinions\" ready\n",
      "\"LibraryThing\" ready\n",
      "\"GoodRead Reviews (w/ spoilers)\" ready\n",
      "\"Drug Recommendations\" ready\n",
      "\"Amazon Ratings (Software)\" ready\n",
      "\"Amazon Ratings (Amazon Fashion)\" ready\n",
      "\"Amazon Ratings (All Beauty)\" ready\n",
      "\"Amazon Ratings (Appliances)\" ready\n",
      "\"Amazon Ratings (Gift Cards)\" ready\n",
      "\"Amazon Ratings (Luxury Beauty)\" ready\n",
      "\"Amazon Ratings (Magazine Subscriptions)\" ready\n",
      "\"Amazon Ratings (Prime Pantry)\" ready\n"
     ]
    }
   ],
   "source": [
    "for dd in DATASETS:\n",
    "    download_and_transform_dataset(dd, verbose=False)\n",
    "    print(f'\"{dd.name}\" ready')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def do_experiment(dataset_descriptor, n_time_splits, strategies, model='svdpp', metric='rmse', bo_init_points=1, bo_n_iter=5):\n",
    "    model_class = None\n",
    "    if model == 'svd':\n",
    "        model_class = SVD\n",
    "    elif model == 'svdpp':\n",
    "        model_class = SVDpp\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model: {model_class}')\n",
    "\n",
    "    def validate_model(strategy: AbstractSplittingStrategy,\n",
    "                       data: np.ndarray,\n",
    "                       validation_data: np.ndarray\n",
    "                       ) -> Tuple[float, float]:\n",
    "        data_X, data_y, val_X, val_y = sort_by_user(data[:, 0:2], data[:, 2], validation_data[:, 0:2],\n",
    "                                                    validation_data[:, 2])\n",
    "\n",
    "        splits = strategy.split(data)\n",
    "        if strategy.generates_many_splits():\n",
    "            splits = [split for split in splits]\n",
    "        else:\n",
    "            splits = [splits]\n",
    "\n",
    "        for i in range(len(splits)):\n",
    "            train, test = splits[i]\n",
    "            X_train, y_train, X_test, y_test = sort_by_user(train[:, 0:2], train[:, 2], test[:, 0:2], test[:, 2])\n",
    "            splits[i] = (X_train, y_train, X_test, y_test)\n",
    "\n",
    "        def function_to_maximize(n_factors, reg):\n",
    "            loss_values = []\n",
    "            for split in splits:\n",
    "                X_train, y_train, X_test, y_test = split\n",
    "                model = model_class(n_factors=round(n_factors), reg=reg)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                if metric == 'rmse':\n",
    "                    loss_values.append(-rmse(expected=y_test, actual=y_pred))\n",
    "                elif metric == 'ndcg':\n",
    "                    loss_values.append(ndcg_at_k(X=X_test, y_expected=y_test, y_actual=y_pred))\n",
    "                else:\n",
    "                    raise ValueError(f'Unknown metric: {metric}')\n",
    "\n",
    "            return sum(loss_values) / len(loss_values)\n",
    "\n",
    "        pbounds = {\n",
    "            'n_factors': (10, 100),\n",
    "            'reg': (0.005, 0.1)\n",
    "        }\n",
    "        optimizer = BayesianOptimization(\n",
    "            f=function_to_maximize,\n",
    "            pbounds=pbounds,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        optimizer.maximize(init_points=bo_init_points, n_iter=bo_n_iter)\n",
    "\n",
    "        model = model_class(n_factors=round(optimizer.max['params']['n_factors']), reg=optimizer.max['params']['reg'])\n",
    "        model.fit(data_X, data_y)\n",
    "        y_pred = model.predict(val_X)\n",
    "\n",
    "        if metric == 'rmse':\n",
    "            metric_value = rmse(expected=val_y, actual=y_pred)\n",
    "        elif metric == 'ndcg':\n",
    "            metric_value = ndcg_at_k(X=val_X, y_expected=val_y, y_actual=y_pred)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown metric: {metric}')\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        return metric_value, end_time - start_time\n",
    "\n",
    "    all_data = as_numpy(dataset_descriptor, only_ratings=False)\n",
    "\n",
    "    validation_data_chunks = []\n",
    "    data = all_data\n",
    "    for i in range(n_time_splits):\n",
    "        data, validation_data = TimeBasedSplittingStrategy(test_size=0.1).split(data)\n",
    "        validation_data_chunks.append(validation_data)\n",
    "    validation_data_chunks.reverse()\n",
    "\n",
    "    res_columns = pd.MultiIndex.from_product([[str(s) for s in strategies], [metric, 'time']],\n",
    "                                             names=['strategy', 'metric'])\n",
    "    res = pd.DataFrame(columns=res_columns, index=range(n_time_splits))\n",
    "\n",
    "    gc.disable()\n",
    "    try:\n",
    "        for i in range(len(validation_data_chunks)):\n",
    "            validation_data = validation_data_chunks[i]\n",
    "\n",
    "            for strategy in strategies:\n",
    "                result_metric, evaluation_time = validate_model(strategy, data, validation_data)\n",
    "                res.loc[i][str(strategy), metric] = result_metric\n",
    "                res.loc[i][str(strategy), 'time'] = evaluation_time\n",
    "                gc.collect()\n",
    "\n",
    "            data = np.r_[data, validation_data]\n",
    "    finally:\n",
    "        gc.enable()\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def do_experiment_or_load_results(results_file: str, *do_exp_args, **do_exp_kwargs):\n",
    "    results_file_path = None\n",
    "    if results_file is not None:\n",
    "        results_file_path = os.path.join(RESULTS_DIR, results_file)\n",
    "        if os.path.exists(results_file_path):\n",
    "            res = pd.read_csv(results_file_path, header=[0, 1])\n",
    "            res.set_index(res.columns[0], inplace=True)\n",
    "            res.columns = pd.MultiIndex.from_tuples(res.columns)\n",
    "            return res\n",
    "\n",
    "    res = do_experiment(*do_exp_args, **do_exp_kwargs)\n",
    "    if results_file_path is not None:\n",
    "        res.to_csv(results_file_path)\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml100k_svd_rmse_261021_1.csv ready\n",
      "ml100k_svdpp_rmse_261021_1.csv ready\n",
      "ml1m_svd_rmse_261021_1.csv ready\n",
      "ml1m_svdpp_rmse_261021_1.csv ready\n",
      "ml10m_svd_rmse_261021_1.csv ready\n",
      "ml10m_svdpp_rmse_261021_1.csv ready\n",
      "ep_svd_rmse_261021_1.csv ready\n",
      "ep_svdpp_rmse_261021_1.csv ready\n",
      "libt_svd_rmse_261021_1.csv ready\n",
      "libt_svdpp_rmse_261021_1.csv ready\n",
      "gr_s_svd_rmse_261021_1.csv ready\n",
      "gr_s_svdpp_rmse_261021_1.csv ready\n",
      "drug_rec_svd_rmse_261021_1.csv ready\n",
      "drug_rec_svdpp_rmse_261021_1.csv ready\n",
      "amz_software_svd_rmse_261021_1.csv ready\n",
      "amz_software_svdpp_rmse_261021_1.csv ready\n",
      "amz_amazon_fashion_svd_rmse_261021_1.csv ready\n",
      "amz_amazon_fashion_svdpp_rmse_261021_1.csv ready\n",
      "amz_all_beauty_svd_rmse_261021_1.csv ready\n",
      "amz_all_beauty_svdpp_rmse_261021_1.csv ready\n",
      "amz_appliances_svd_rmse_261021_1.csv ready\n",
      "amz_appliances_svdpp_rmse_261021_1.csv ready\n",
      "amz_gift_cards_svd_rmse_261021_1.csv ready\n",
      "amz_gift_cards_svdpp_rmse_261021_1.csv ready\n",
      "amz_luxury_beauty_svd_rmse_261021_1.csv ready\n",
      "amz_luxury_beauty_svdpp_rmse_261021_1.csv ready\n",
      "amz_magazine_subscriptions_svd_rmse_261021_1.csv ready\n",
      "amz_magazine_subscriptions_svdpp_rmse_261021_1.csv ready\n",
      "amz_prime_pantry_svd_rmse_261021_1.csv ready\n",
      "amz_prime_pantry_svdpp_rmse_261021_1.csv ready\n"
     ]
    }
   ],
   "source": [
    "for dd in DATASETS:\n",
    "    for model in ['svd', 'svdpp']:\n",
    "        _ = do_experiment_or_load_results(\n",
    "            f'{dd.id}_{model}_rmse_261021_1.csv',\n",
    "            dataset_descriptor=dd,\n",
    "            n_time_splits=5,\n",
    "            metric='rmse',\n",
    "            model=model,\n",
    "            strategies=[\n",
    "                RandomStrategy(test_size=0.2),\n",
    "                CrossValidationRandomStrategy(n_folds=5),\n",
    "                TimeBasedSplittingStrategy(test_size=0.2),\n",
    "                TemporalUserSplittingStrategy(test_size=0.2)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(f'{dd.id}_{model}_rmse_261021_1.csv ready')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml100k_svd_ndcg_271021_1.csv ready\n",
      "ml100k_svdpp_ndcg_271021_1.csv ready\n",
      "ml1m_svd_ndcg_271021_1.csv ready\n",
      "ml1m_svdpp_ndcg_271021_1.csv ready\n",
      "ml10m_svd_ndcg_271021_1.csv ready\n",
      "ml10m_svdpp_ndcg_271021_1.csv ready\n",
      "ep_svd_ndcg_271021_1.csv ready\n",
      "ep_svdpp_ndcg_271021_1.csv ready\n",
      "libt_svd_ndcg_271021_1.csv ready\n",
      "libt_svdpp_ndcg_271021_1.csv ready\n",
      "gr_s_svd_ndcg_271021_1.csv ready\n",
      "gr_s_svdpp_ndcg_271021_1.csv ready\n",
      "drug_rec_svd_ndcg_271021_1.csv ready\n",
      "drug_rec_svdpp_ndcg_271021_1.csv ready\n",
      "amz_software_svd_ndcg_271021_1.csv ready\n",
      "amz_software_svdpp_ndcg_271021_1.csv ready\n",
      "amz_amazon_fashion_svd_ndcg_271021_1.csv ready\n",
      "amz_amazon_fashion_svdpp_ndcg_271021_1.csv ready\n",
      "amz_all_beauty_svd_ndcg_271021_1.csv ready\n",
      "amz_all_beauty_svdpp_ndcg_271021_1.csv ready\n",
      "amz_appliances_svd_ndcg_271021_1.csv ready\n",
      "amz_appliances_svdpp_ndcg_271021_1.csv ready\n",
      "amz_gift_cards_svd_ndcg_271021_1.csv ready\n",
      "amz_gift_cards_svdpp_ndcg_271021_1.csv ready\n",
      "amz_luxury_beauty_svd_ndcg_271021_1.csv ready\n",
      "amz_luxury_beauty_svdpp_ndcg_271021_1.csv ready\n",
      "amz_magazine_subscriptions_svd_ndcg_271021_1.csv ready\n",
      "amz_magazine_subscriptions_svdpp_ndcg_271021_1.csv ready\n",
      "amz_prime_pantry_svd_ndcg_271021_1.csv ready\n",
      "amz_prime_pantry_svdpp_ndcg_271021_1.csv ready\n"
     ]
    }
   ],
   "source": [
    "for dd in DATASETS:\n",
    "    for model in ['svd', 'svdpp']:\n",
    "        _ = do_experiment_or_load_results(\n",
    "            f'{dd.id}_{model}_ndcg_271021_1.csv',\n",
    "            dataset_descriptor=dd,\n",
    "            n_time_splits=5,\n",
    "            metric='ndcg',\n",
    "            model=model,\n",
    "            strategies=[\n",
    "                RandomStrategy(test_size=0.2),\n",
    "                CrossValidationRandomStrategy(n_folds=5),\n",
    "                TimeBasedSplittingStrategy(test_size=0.2),\n",
    "                TemporalUserSplittingStrategy(test_size=0.2)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(f'{dd.id}_{model}_ndcg_271021_1.csv ready')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}